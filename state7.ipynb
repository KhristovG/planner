{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_gigachat import GigaChat\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Загружаем переменные окружения из .env файла\n",
    "load_dotenv()\n",
    "\n",
    "# Получаем API-ключ из переменной окружения\n",
    "creds = os.getenv('credentials')\n",
    "token = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Моки сценариев и функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_return_scenario = [\"\"\"\n",
    "Сценарий определения погоды:\n",
    "1) Определи, где пользователь хочет узнать погоду.\n",
    "2) Определи погоду в данной местности и сообщи пользователю результат.\n",
    "\"\"\",\n",
    "# \"\"\"Сценарий потери банковской карты:\n",
    "# Если пользователь потерял или сломал банковскую карту, есть 4 основных этапа:\n",
    "# 1) Определи, какие у пользователя есть карты. (например у пользователя есть следующие карты ***1234, ***2345 или ***3456)\n",
    "# 2) Предложи заблокировать эту карту.\n",
    "# 3) Предложи пользователю перевыпустить карту. (например перевыпустить на карту Momentum либо на карту постоянного пользования)\n",
    "# 4) Предложи пользователю доставить карту. (например с помощью сервиса доставки \"Самокат\" либо самовывозом)\"\"\",\n",
    "\"\"\"\n",
    "Сценарий перевода денежных средств на другую карту пользователя (перевод самому себе):\n",
    "1) Определи, какие у пользователя есть карты. (например у пользователя есть следующие карты ***9876, ***5432 или ***1098).\n",
    "2) Узнай у пользователя с какой карты и на какую карту он хочет перевести деньги.\n",
    "3) Убедись, что у пользователя есть необходимое количество средств, в случае успеха получи от пользователя подтверждение на перевод, в случае недостатка средств сообщи об этом пользователю.\n",
    "4) Сделай перевод и уведоми об этом пользователя.\n",
    "\"\"\",\n",
    "]\n",
    "rag_return_func = \"\"\"Для выполнения задачи у тебя есть следующие функции:\n",
    "- `get_user_cards()`: Функция для возврата списка имеющихся у пользователя карт.\n",
    "- `block_card()`: Функция для блокировки карты.\n",
    "- `reissue_card()`: Функция для перевыпуска карты.\n",
    "- `deliver_card()`: Функция для доставки карты пользователю.\n",
    "- `card_balance()`: Функция для определения баланса на карте.\n",
    "- `transefer_money()`: Функция для перевода денег с карты на карту.\n",
    "- `destination_weather()`: Функция для определения погоды в конкретной местности.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Tuple, Union, Literal, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"План по которому будет действовать агент-исполнитель\"\"\"\n",
    "    steps: List[str] = Field(\n",
    "        description=\"Шаги, которые должны быть выполнены. Каждый этап начинается с цифры и скобки, например, '1) первый этап'.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нужно будет придумать логику бинда функций для разных задач, мы же не будем биндить сразу все доступные функции\n",
    "\n",
    "# Set up the tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import MessagesState, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "@tool\n",
    "def get_user_cards(cards_name: str):\n",
    "    \"\"\"Выдаёт пользователю список карт, которые у него есть.\"\"\"\n",
    "    cards_name = ['***1234', '***2345','***3456']\n",
    "    # Логика для получения списка карт пользователя через API или другой механизм.У пользователя есть следующие карты ***1234, ***2345 или ***3456\n",
    "    return f'Список доступных карт: {cards_name}'\n",
    "\n",
    "@tool\n",
    "def block_card(card_name: str):\n",
    "    \"\"\"Заблокировать карту\"\"\"\n",
    "    # Логика для блокировки карты через API или другой механизм\n",
    "    return f\"Карта {card_name} успешно заблокирована.\"\n",
    "\n",
    "@tool\n",
    "def reissue_card(card_name: str, new_card_type: str = \"Momentum\"):\n",
    "    \"\"\"Перевыпустить карту. Например, можно выбрать карту типа Momentum или карту постоянного пользования.\"\"\"\n",
    "    # Логика перевыпуска карты\n",
    "    return f\"Перевыпущена карта типа {new_card_type}.\"\n",
    "\n",
    "@tool\n",
    "def deliver_card(delivery_method: str = \"Самокат\"):\n",
    "    \"\"\"Организовать доставку карты. Можно выбрать способ доставки: 'Самокат' или самовывоз.\"\"\"\n",
    "    if delivery_method.lower() == \"самокат\":\n",
    "        return \"Карта будет доставлена с помощью службы доставки 'Самокат'.\"\n",
    "    elif delivery_method.lower() == \"самовывоз\":\n",
    "        return \"Вы можете забрать карту в пункте самовывоза.\"\n",
    "    else:\n",
    "        return \"Выберите один из доступных методов доставки: 'Самокат' или 'Самовывоз'.\"\n",
    "    \n",
    "@tool\n",
    "def card_balance(card_name: str, balance):\n",
    "    \"\"\"Узнать баланс на карте\"\"\"\n",
    "    # Логика для получения баланса карты через API или другой механизм\n",
    "    return f\"На карте {card_name} есть {balance} средств.\"\n",
    "\n",
    "@tool\n",
    "def transefer_money(card_name: str, card_name_to: str, balance):\n",
    "    \"\"\"Перевести деньги с карты на карту\"\"\"\n",
    "    # Логика для перевода денег с карты на карту через API или другой механизм\n",
    "    return f\"Переведено {balance} с  карты {card_name} на карту {card_name_to}.\"\n",
    "\n",
    "@tool\n",
    "def destination_weather(destinatio: str):\n",
    "    \"\"\"Определение погоды в данной местности\"\"\"\n",
    "    # Логика для определения погоды в данной местности через API или другой механизм\n",
    "    return f\"В {destinatio} следующая погода.\"\n",
    "\n",
    "tools = [get_user_cards, block_card, reissue_card, deliver_card, card_balance, transefer_money, destination_weather]\n",
    "tool_node = ToolNode(tools)\n",
    "memory = MemorySaver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Промпты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts and models\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# планнер сценарный\n",
    "planner_template = \"\"\"\n",
    "Ты — агент-планировщик. Твоя задача — разработать подробный и последовательный план действий для решения проблемы, исходя из предоставленного сценария и доступных функций. План будет передан агенту-исполнителю для выполнения.\n",
    "\n",
    "Задание:\n",
    "Тебе нужно создать план, основываясь на самых релевантных для запроса пользователя сценариях и списке доступных функций.\n",
    "\n",
    "Сценарии: {scenario}\n",
    "\n",
    "Функции: {functions}\n",
    "\n",
    "Диалог c пользователем: {messages}\n",
    "\n",
    "Твой план должен соответствовать следующим требованиям:\n",
    "1. **Разработай последовательность шагов**, которая максимально эффективно решает проблему, учитывая сценарий и доступные функции.\n",
    "2. **Определи возможные пробелы** в информации, которые могут потребовать уточнения от пользователя, и составь план так, чтобы на важных этапах ты мог запросить дополнительные разъяснения.\n",
    "3. **Запроси разрешение** у пользователя на выполнение критичных операций, таких как изменение данных или выполнение действий, которые могут повлиять на дальнейшие шаги.\n",
    "4. Учитывай, что **агент-исполнитель будет подробно описывать каждый шаг**, который он будет выполнять, а также будет указывать, какие функции использует на каждом этапе. Поэтому убедись, что каждый этап описан максимально четко.\n",
    "5. Если какие-то шаги требуют предварительных условий или зависимостей, укажи это.\n",
    "\n",
    "**Итоговый формат плана:**\n",
    "Составь список шагов в следующем формате:\n",
    "1) Описание первого шага: конкретное действие, использованные функции, возможные уточнения.\n",
    "2) Описание второго шага: конкретное действие, использованные функции, возможные уточнения.\n",
    "3) Описание третьего шага: конкретное действие, использованные функции, возможные уточнения.\n",
    "... и так далее.\n",
    "\n",
    "В конце каждый шаг должен быть записан в формате: \"N) описание шага\".\n",
    "\n",
    "Убедись, что план логичен, последовательный и детализированный.\n",
    "\"\"\"\n",
    "planner_prompt = ChatPromptTemplate.from_template(planner_template)\n",
    "\n",
    "planner = planner_prompt | ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", temperature=0\n",
    ").with_structured_output(Plan, include_raw=True)\n",
    "\n",
    "#грейдер оценка по плану\\нет\n",
    "class GradePlan(BaseModel):\n",
    "    \"\"\"Релевантен ли запрос текущему плану\"\"\"\n",
    "\n",
    "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
    "        ...,\n",
    "        description=\"Релевантен ли запрос плану yes или no\",\n",
    "    )\n",
    "\n",
    "\n",
    "grader_prompt = \"\"\" Ты оцениваешь релевантность запроса пользователя по отношению к текущему плану в два этапа:\n",
    "\n",
    "Этап 1: Оценка релевантности запроса текущему плану\n",
    "Проанализируй запрос пользователя в контексте текущего плана. Если запрос содержит информацию, связанную с этим планом (например, этапы, задачи или темы, упомянутые в плане), оцени его как релевантный (yes).\n",
    "Обрати внимание, что пользователь может уже пройти часть плана, поэтому внимательно проверь соответствие запроса каждому этапу.\n",
    "Дай бинарную оценку:\n",
    "\n",
    "yes — запрос релевантен текущему плану\n",
    "no — запрос не связан с текущим планом\n",
    "Не возвращай итоговый ответ на данном этапе, сперва пройди этап 2.\n",
    "\n",
    "Диалог с пользователем:\n",
    "(Основное внимание удели последним репликам пользователя)\n",
    "{messages}\n",
    "\n",
    "Текущий план:\n",
    "{plan}\n",
    "\n",
    "Этап 2: Проверка на более релевантный сценарий\n",
    "Если на первом этапе ты дал ответ \"yes\", то проверь, есть ли более релевантный сценарий среди предзагруженных сценариев. Если такой сценарий найден, верни \"no\". Если связанного сценария нет, оставь ответ \"yes\".\n",
    "\n",
    "Предзагруженные сценарии:\n",
    "{rag_return_scenario}\n",
    "\n",
    "Пример 1:\n",
    "Первый этап:\n",
    "Диалог с пользователем: \n",
    "humanmessage: потерял сумку\n",
    "aimessage: Мне очень жаль слышать, что вы потеряли сумку. Можете, пожалуйста, сообщить, когда и где именно вы ее потеряли? Эта информация поможет мне понять, возможно ли вернуть сумку.\n",
    "humanmessage: в ней была карта\n",
    "Текущий план:\n",
    "1) Запросить у пользователя информацию о сумку: когда и где он ее потерял, чтобы понять, возможно ли ее найти или вернуть.\n",
    "2) Уточнить, есть ли у пользователя возможность обратиться в место, где он потерял сумку (например, в магазин, кафе и т.д.), и предложить помощь в этом.\n",
    "3) Если сумка была потеряна в общественном месте, предложить пользователю обратиться в службу находок или в полицию, если это необходимо.\n",
    "4) Обсудить возможность покупки новой сумки, если старая не найдется, и предложить варианты, если пользователь заинтересован.\n",
    "Результат первого этапа: yes. Так как диалог связан с текущим планом\n",
    "Второй этап: \n",
    "Предзагруженные сценарии:\n",
    "[\"Сценарий потери карты:\n",
    "Если пользователь потерял или сломал карту, есть 4 основных этапа:\n",
    "1) Определи, о какой карте идет речь. (например у пользователя есть следующие карты ***1234, ***2345 или ***3456)\n",
    "2) Предложи заблокировать эту карту.\n",
    "3) Предложи пользователю перевыпустить карту. (например перевыпустить на карту Momentum либо на карту постоянного пользования)\n",
    "4) Предложи пользователю доставить карту. (например с помощью сервиса доставки 'Самокат' либо самовывозом)\"]\n",
    "Результат второго этапа: no. Так как нашёлся более релевантный сценарий \"потеря карты\". Оценка по предзагруженным сценариям всегда в приоритете.\n",
    "Итоговый ответ: no\n",
    "\"\"\"\n",
    "planner_grader_prompt = ChatPromptTemplate.from_template(grader_prompt)\n",
    "\n",
    "planner_grader = planner_grader_prompt | ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", temperature=0\n",
    ").with_structured_output(GradePlan, include_raw=True)\n",
    "\n",
    "#грейдер оценка есть ли сценарий для формирования первичного плана\n",
    "class GradeScenario(BaseModel):\n",
    "    \"\"\"Есть ли релевантный сценарий для данного запроса\"\"\"\n",
    "\n",
    "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
    "        ...,\n",
    "        description=\"Релевантен ли запрос какому-либо сценарию yes или no\",\n",
    "    )\n",
    "\n",
    "grader_scen_prompt = \"\"\"\n",
    "Задача: Ты оцениваешь есть ли релевантный сценарий для данного запроса пользователя.\n",
    "\n",
    "Проанализируй предоставленные сценарии и запрос пользователя. Если запрос содержит информацию, связанную с каким-то из предоставленных сценариев, оцени его как релевантный (yes).\n",
    "Дай бинарную оценку:\n",
    "\n",
    "yes — для данного запроса есть релевантый сценарий\n",
    "no — для данного запроса нет релевантного сценария\n",
    "\n",
    "Предзагруженные сценарии:\n",
    "{rag_return_scenario}\n",
    "\n",
    "Запрос пользователя:\n",
    "{messages}\n",
    "\"\"\"\n",
    "\n",
    "planner_grade_scen_prompt = ChatPromptTemplate.from_template(grader_scen_prompt)\n",
    "\n",
    "planner_scen_grader = planner_grade_scen_prompt | ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", temperature=0\n",
    ").with_structured_output(GradeScenario, include_raw=True)\n",
    "\n",
    "# grader выполнен план или нет\n",
    "class GraderCompletion(BaseModel):\n",
    "    \"\"\"Оценка завершённости плана\"\"\"\n",
    "\n",
    "    completion_score: Literal['0', '1', '2'] = Field(\n",
    "        ...,\n",
    "        description=\"Оценка завершённости плана: '0' — не завершён, '1' — завершён, '2' — неактуален(пользователь передумал либо отказался)\"\n",
    "    )\n",
    "\n",
    "completion_grader_prompt = \"\"\"\n",
    "Ты — агент, оценивающий завершенность текущего плана.\n",
    "\n",
    "Задание:\n",
    "Твоя задача — проанализировать текущий план и определить его степень завершенности. Для этого оцени, насколько полностью выполнены все этапы плана, и выбери одно из следующих значений:\n",
    "\n",
    "0) План не завершён — еще есть этапы, которые нужно выполнить.\n",
    "1) План завершён — все этапы выполнены, план завершен.\n",
    "2) План неактуален — пользователь передумал либо отказался.\n",
    "\n",
    "Внимание:\n",
    "Основываясь на текущем плане и диалоге с пользователем оценить завершённость плана. Убедись, что твоя оценка точно отражает текущее состояние.\n",
    "\n",
    "Текущий план:\n",
    "{plan}\n",
    "Диалог с пользователем:\n",
    "{messages}\n",
    "\n",
    "Оценка завершенности плана (выбери один из вариантов: '0', '1' или '2'): \n",
    "\"\"\"\n",
    "\n",
    "completion_status_prompt_template = ChatPromptTemplate.from_template(completion_grader_prompt)\n",
    "\n",
    "completion_status_agent = completion_status_prompt_template | ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", temperature=0\n",
    ").with_structured_output(GraderCompletion, include_raw=True)\n",
    "\n",
    "# динамический планер\n",
    "replanner_template = \"\"\"\n",
    "Задача: Ты — агент-планировщик. Твоя задача — разработать последовательный и детализированный план действий на основе текущей потребности пользователя и уже существующих планов, функций.\n",
    "\n",
    "Информация для работы:\n",
    "Диалог с пользователем (в приоритете для составления плана должны быть последние сообщения именно от пользователя):\n",
    "{messages}\n",
    "Предзагруженные планы (приоритетные планы, если они подходят):\n",
    "{pred_plans}\n",
    "Доступные тебе функции:\n",
    "{functions}\n",
    "Все планы (включая не приоритетные):\n",
    "{all_plans}\n",
    "\n",
    "Основные указания:\n",
    "1. Проверь текущие планы: Прежде чем составлять новый план, проверь, может ли быть использован один из уже существующих планов. Рассматривай предзагруженные планы в первую очередь.\n",
    "2. Если можно использовать уже сущестующий план просто верни его без изменений. Если подходящего готового плана нет начинай выполнение следующих указаний.\n",
    "3. Действуй по текущей потребности: Составь план, который решает исключительно текущую потребность пользователя (то есть самую последнюю).\n",
    "4. Запрашивай уточнения: Если для выполнения плана необходимы дополнительные уточнения от пользователя, укажи это на соответствующих этапах.\n",
    "5. Согласовывай критичные операции: Если шаги плана предполагают изменения данных или выполнения действий, которые могут повлиять на другие этапы или информацию пользователя, обязательно запроси разрешение.\n",
    "6. Четкость и последовательность: Каждый шаг должен быть максимально четким и подробным, чтобы агент-исполнитель мог выполнить его без дополнительных разъяснений.\n",
    "7. Учитывай зависимости и предварительные условия: Если некоторые шаги зависят от других условий или требуют выполнения заранее, обязательно укажи это.\n",
    "\n",
    "Формат итогового плана:\n",
    "1) Описание действия, используемые функции, возможные уточнения.\n",
    "2) Описание действия, используемые функции, возможные уточнения.\n",
    "3) Описание действия, используемые функции, возможные уточнения.\n",
    "И так далее.\n",
    "Каждый шаг должен быть записан в формате:\n",
    "N) Описание шага: конкретное действие, используемые функции, возможные уточнения.\n",
    "\n",
    "Особенности:\n",
    "\n",
    "На общие фразы (например, «привет», «пока», «как дела», «как настроение») не нужно создавать большие планы. В таких случаях достаточно вернуть план типа: «Просто болтай с пользователем».\n",
    "План должен быть логичным, последовательным и детализированным.\n",
    "\"\"\"\n",
    "\n",
    "replanner_prompt = ChatPromptTemplate.from_template(replanner_template)\n",
    "\n",
    "replanner = replanner_prompt | ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", temperature=0\n",
    ").with_structured_output(Plan, include_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# экзекьютор\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "def get_executor(plan):\n",
    "    executor_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", f\"\"\"Ты — эмпатичный агент-исполнитель. Твоя задача — выполнить план действий, который ты получил от агента-планировщика. Следуй по плану, при этом уточняй информацию или предпринимай дополнительные шаги, если это необходимо.\n",
    "    План:\n",
    "    {plan}\n",
    "    В процессе выполнения задач, если на каком-то этапе тебе не хватает информации или неясности по действиям, уточни их у пользователя.\n",
    "    Пожалуйста, начни выполнение задач, следуя указанному плану. В конце своего ответа добавь \"SYS\": и опиши какой этап плана ты только что выполнил, также опиши свои действия (например какие функции ты использовал) и что ты будешь делать дальше.\n",
    "    Информацию о функциях можно передавать только после SYS.\n",
    "    \"\"\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    model = model.bind_tools(tools, parallel_tool_calls=False)\n",
    "    chain = {\"input\": RunnablePassthrough()} | executor_prompt | model\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Граф"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "# ОЦЕНКУ ПЛАНА ПОКА УБИРАЮ только токены пока ест закоменченный снизу код это для него + ноутбук state5\n",
    "\n",
    "# class ComplexState(TypedDict):\n",
    "#     plan: Tuple[List[str],str]\n",
    "#     all_plans: List[Union[Tuple[List[str], int], List[str]]]\n",
    "#     pred_plans: Tuple[List[str],str]\n",
    "#     messages: Annotated[list[HumanMessage | AIMessage | ToolMessage], add_messages]\n",
    "\n",
    "class ComplexState(TypedDict):\n",
    "    plan: List[str]\n",
    "    all_plans: List[List[str]]\n",
    "    pred_plans: List[List[str]]\n",
    "    messages: Annotated[list[HumanMessage | AIMessage | ToolMessage], add_messages]\n",
    "    vremya_dengi: dict[str,str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "# Define the function that calls the all models\n",
    "def call_model(state):\n",
    "    # print('state_begin')\n",
    "    start_time = time.time()\n",
    "    print(state)\n",
    "    # print('----------')\n",
    "    pred_plans = state.get(\"pred_plans\")\n",
    "    all_plans = state.get(\"all_plans\")\n",
    "    plan = state.get(\"plan\")\n",
    "    messages = state.get(\"messages\")\n",
    "    tokens = 0\n",
    "    if plan is None:  # Check if plan is empty\n",
    "        # print('1')\n",
    "        pred_plans = []\n",
    "        # логика старта посмотри в сценариях если есть схожие\n",
    "        score_scen = planner_scen_grader.invoke({\"rag_return_scenario\": rag_return_scenario, \"messages\": state['messages']})\n",
    "        # tokens+=score_scen.usage_metadata['total_tokens']\n",
    "        tokens+=score_scen['raw'].response_metadata['token_usage']['total_tokens']\n",
    "        if score_scen['parsed'].binary_score == 'yes':\n",
    "\n",
    "            # print('rag')\n",
    "            # global ps\n",
    "            plan_pr = planner.invoke({\"scenario\": rag_return_scenario, \"functions\": rag_return_func, \"messages\": state['messages']})\n",
    "            # ps = plan_pr\n",
    "            tokens+=plan_pr['raw'].response_metadata['token_usage']['total_tokens']\n",
    "            pred_plans.append(plan_pr['parsed'].steps)\n",
    "            plan = plan_pr['parsed'].steps\n",
    "        else: \n",
    "            # print('nerag')\n",
    "            plan = replanner.invoke({\"messages\":messages,\"pred_plans\":pred_plans, \"all_plans\":all_plans, 'functions':rag_return_func})\n",
    "            tokens+=plan['raw'].response_metadata['token_usage']['total_tokens']\n",
    "            plan = plan['parsed'].steps\n",
    "        \n",
    "        print('---Первичный план--')\n",
    "        print(\"\\n\".join(plan))\n",
    "        print('----------')\n",
    "        state['plan'] = plan\n",
    "        # print(all_plans)\n",
    "        chain = get_executor(plan=plan)\n",
    "        \n",
    "        response = chain.invoke(messages)\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        tokens+= response.usage_metadata['total_tokens']\n",
    "        vremya_dengi = {'time':total_time,'tokens':tokens}\n",
    "        response = AIMessage(content=response.content, tool_calls=response.tool_calls)\n",
    "        return {\"messages\": [response],'plan':plan, 'all_plans':all_plans, \"pred_plans\":pred_plans, 'vremya_dengi':vremya_dengi}\n",
    "    else:\n",
    "        # print('2')\n",
    "        score_plan_grade = planner_grader.invoke({\"plan\":plan,\"rag_return_scenario\":rag_return_scenario,\"messages\":messages[-1]})\n",
    "        tokens+= score_plan_grade['raw'].response_metadata['token_usage']['total_tokens']\n",
    "        if score_plan_grade['parsed'].binary_score == 'yes': #по плану\n",
    "            print('po plany')\n",
    "            plan = state['plan']\n",
    "            # print(state['pred_plans'])\n",
    "            print('---Текущий план--')\n",
    "            print(plan)\n",
    "            print(\"\\n\".join(plan))\n",
    "            print('----------')\n",
    "            chain = get_executor(plan=plan)\n",
    "            response = chain.invoke(messages)\n",
    "            end_time = time.time()\n",
    "            total_time = end_time - start_time\n",
    "            tokens+= response.usage_metadata['total_tokens']\n",
    "            vremya_dengi = {'time':total_time,'tokens':tokens}\n",
    "            # print('state_end_yes')\n",
    "            # print(state)\n",
    "            # print('----------')\n",
    "            response = AIMessage(content=response.content, tool_calls=response.tool_calls)\n",
    "            # print(state['messages'])\n",
    "            return {\"messages\": [response],'plan':plan, 'all_plans':all_plans, \"pred_plans\":pred_plans, 'vremya_dengi':vremya_dengi}\n",
    "        else: #не по плану\n",
    "            print('ne po plany')\n",
    "            score_scen_2 = planner_scen_grader.invoke({\"rag_return_scenario\": rag_return_scenario, \"messages\": state['messages'][-1]})\n",
    "            tokens+= score_scen_2['raw'].response_metadata['token_usage']['total_tokens']\n",
    "            print(state['messages'][-1])\n",
    "            if score_scen_2['parsed'].binary_score == 'yes':\n",
    "                print('rag ne po plany')\n",
    "                plan_pr = planner.invoke({\"scenario\": rag_return_scenario, \"functions\": rag_return_func, \"messages\": state['messages']})\n",
    "                tokens+= plan_pr['raw'].response_metadata['token_usage']['total_tokens']\n",
    "                plan_pr = plan_pr['parsed'].steps\n",
    "                pred_plans.append(plan_pr)\n",
    "                plan = plan_pr\n",
    "            else: \n",
    "                print('nerag ne po plany')\n",
    "                plan = replanner.invoke({\"messages\":messages[-1],\"pred_plans\":pred_plans, \"all_plans\":all_plans,'functions':rag_return_func})\n",
    "                tokens+= plan['raw'].response_metadata['token_usage']['total_tokens']\n",
    "                plan = plan['parsed'].steps\n",
    "                # plan = replanner.invoke({\"messages\":messages[-1], \"pred_plans\":pred_plans, \"all_plans\":all_plans}).steps #messages[-7:]\n",
    "            #тут надо логику что новый или возвращение к старому план\n",
    "            all_plans = []\n",
    "            plans_for_print = []\n",
    "            for pred in pred_plans:\n",
    "                plans_for_print.append(pred)\n",
    "            for pl in all_plans:\n",
    "                plans_for_print.append(pl)\n",
    "            if plan in plans_for_print:\n",
    "                print('---Текущий план---')\n",
    "                print(\"\\n\".join(plan))\n",
    "                print('----------')\n",
    "                # all_plans.append(plan_compl)\n",
    "                chain = get_executor(plan=plan)\n",
    "                response = chain.invoke(messages)\n",
    "                end_time = time.time()\n",
    "                total_time = end_time - start_time\n",
    "                tokens+= response.usage_metadata['total_tokens']\n",
    "                vremya_dengi = {'time':total_time,'tokens':tokens}\n",
    "                # print('state_end_no')\n",
    "                # print(state)\n",
    "                # print('----------')\n",
    "                response = AIMessage(content=response.content, tool_calls=response.tool_calls)\n",
    "                return {\"messages\": [response],'plan':plan, 'all_plans':all_plans, \"pred_plans\":pred_plans, 'vremya_dengi':vremya_dengi}\n",
    "            else:\n",
    "                print('---Текущий план--')\n",
    "                # print(plan)\n",
    "                print(\"\\n\".join(plan))\n",
    "                print('----------')\n",
    "                all_plans.append(plan)\n",
    "                chain = get_executor(plan=plan)\n",
    "                response = chain.invoke(messages)\n",
    "                end_time = time.time()\n",
    "                total_time = end_time - start_time\n",
    "                tokens+= response.usage_metadata['total_tokens']\n",
    "                vremya_dengi = {'time':total_time,'tokens':tokens}\n",
    "                # print('state_end_no')ё\n",
    "                # print(state)\n",
    "                # print('----------')\n",
    "                response = AIMessage(content=response.content, tool_calls=response.tool_calls)\n",
    "                return {\"messages\": [response],'plan':plan, 'all_plans':all_plans, \"pred_plans\":pred_plans, 'vremya_dengi':vremya_dengi}\n",
    "\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(ComplexState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agents\", call_model)\n",
    "workflow.add_node(\"action\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agents\")\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agents\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"action\", \"agents\")\n",
    "\n",
    "# Set up memory\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "заблокируй и доставь карту\n",
      "{'messages': [HumanMessage(content='заблокируй и доставь карту', additional_kwargs={}, response_metadata={}, id='ca85bab8-7884-4e25-ac53-02e5246f642e')]}\n",
      "---Первичный план--\n",
      "1) Получить список имеющихся у пользователя карт: используем функцию get_user_cards().\n",
      "2) Запросить у пользователя, какую именно карту он хочет заблокировать: необходимо уточнить, если у пользователя несколько карт.\n",
      "3) Заблокировать выбранную карту: используем функцию block_card().\n",
      "4) Запросить у пользователя, какую карту он хочет получить на доставку: необходимо уточнить, если у пользователя несколько карт.\n",
      "5) Доставить выбранную карту пользователю: используем функцию deliver_card().\n",
      "----------\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_user_cards (call_0nYvnbuqXRx4SYoiVJ4ncfJs)\n",
      " Call ID: call_0nYvnbuqXRx4SYoiVJ4ncfJs\n",
      "  Args:\n",
      "    cards_name: user\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_user_cards\n",
      "\n",
      "Список доступных карт: ['***1234', '***2345', '***3456']\n",
      "{'plan': ['1) Получить список имеющихся у пользователя карт: используем функцию get_user_cards().', '2) Запросить у пользователя, какую именно карту он хочет заблокировать: необходимо уточнить, если у пользователя несколько карт.', '3) Заблокировать выбранную карту: используем функцию block_card().', '4) Запросить у пользователя, какую карту он хочет получить на доставку: необходимо уточнить, если у пользователя несколько карт.', '5) Доставить выбранную карту пользователю: используем функцию deliver_card().'], 'all_plans': None, 'pred_plans': [], 'messages': [HumanMessage(content='заблокируй и доставь карту', additional_kwargs={}, response_metadata={}, id='ca85bab8-7884-4e25-ac53-02e5246f642e'), AIMessage(content='', additional_kwargs={}, response_metadata={}, id='38f3f88e-8b3d-46f0-90c1-e49311ba5a6e', tool_calls=[{'name': 'get_user_cards', 'args': {'cards_name': 'user'}, 'id': 'call_0nYvnbuqXRx4SYoiVJ4ncfJs', 'type': 'tool_call'}]), ToolMessage(content=\"Список доступных карт: ['***1234', '***2345', '***3456']\", name='get_user_cards', id='4375cc4a-97c5-4754-81e9-644e430bc22d', tool_call_id='call_0nYvnbuqXRx4SYoiVJ4ncfJs')], 'vremya_dengi': {'time': 5.79718804359436, 'tokens': 1895}}\n",
      "po plany\n",
      "---Текущий план--\n",
      "['1) Получить список имеющихся у пользователя карт: используем функцию get_user_cards().', '2) Запросить у пользователя, какую именно карту он хочет заблокировать: необходимо уточнить, если у пользователя несколько карт.', '3) Заблокировать выбранную карту: используем функцию block_card().', '4) Запросить у пользователя, какую карту он хочет получить на доставку: необходимо уточнить, если у пользователя несколько карт.', '5) Доставить выбранную карту пользователю: используем функцию deliver_card().']\n",
      "1) Получить список имеющихся у пользователя карт: используем функцию get_user_cards().\n",
      "2) Запросить у пользователя, какую именно карту он хочет заблокировать: необходимо уточнить, если у пользователя несколько карт.\n",
      "3) Заблокировать выбранную карту: используем функцию block_card().\n",
      "4) Запросить у пользователя, какую карту он хочет получить на доставку: необходимо уточнить, если у пользователя несколько карт.\n",
      "5) Доставить выбранную карту пользователю: используем функцию deliver_card().\n",
      "----------\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "У вас есть следующие карты: '***1234', '***2345', '***3456'. Пожалуйста, уточните, какую именно карту вы хотите заблокировать? \n",
      "\n",
      "SYS: Я выполнил первый этап плана, получив список карт пользователя с помощью функции get_user_cards(). Далее я уточняю у пользователя, какую карту он хочет заблокировать.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "user_input = input(\"Введите ваше сообщение: \")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"423342251wq2dq32рр32h323d259226332l622w32243\"}}\n",
    "# print(app.get_state(config=config))\n",
    "# app.update_state(\n",
    "#     {\"plan\": []},\n",
    "# )\n",
    "while user_input.lower() != \"=\":\n",
    "    for event in app.stream({\"messages\": [HumanMessage(content=user_input)]}, config, stream_mode=\"values\"):\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "        # if \"__end__\" not in event:\n",
    "        #     print(event)\n",
    "        #     print(\"----\")\n",
    "\n",
    "\n",
    "\n",
    "    user_input = input(\"Введите следующее сообщение (или '=' для выхода): \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
